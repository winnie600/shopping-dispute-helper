
---

# ğŸ“ **dispute_pipeline_v3.2 å°ˆæ¡ˆçµæ§‹**

```
dispute_pipeline_v3/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app/
â”‚   â”‚     â””â”€â”€ main.py                 â†ï¼ˆv3.1 æ–°å¢ï¼‰å¾Œç«¯ APIï¼ˆå‰å¾Œç«¯åµŒå…¥ç”¨ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ summary_trigger.py            â†ï¼ˆv3.2 æ–°å¢ï¼‰AI ç¸½çµè§¸ç™¼å™¨ï¼ˆåˆ¤æ–·æ™‚é–“é»ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚     â”œâ”€â”€ __init__.py
â”‚   â”‚     â”œâ”€â”€ extractor.py
â”‚   â”‚     â”œâ”€â”€ rflags.py
â”‚   â”‚     â”œâ”€â”€ llm_stage2.py
â”‚   â”‚     â”œâ”€â”€ postprocess.py
â”‚   â”‚     â”œâ”€â”€ policy.py
â”‚   â”‚     â”œâ”€â”€ outcome_ai.py
â”‚   â”‚     â”œâ”€â”€ summary.py
â”‚   â”‚     â””â”€â”€ build.py                â† æ•´åˆ Stage1/2/3 + Summaryï¼ˆAPI/CLI å…±ç”¨ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ arbitration_pipeline.py       â† ä¸»å…¥å£ï¼ˆCLI ç‰ˆï¼Œèˆ‡èˆŠå–®æª”ç‰ˆåŒåŠŸèƒ½ï¼‰
â”‚   â””â”€â”€ initial_judgement_chatbot.py  â† åˆåˆ¤èŠå¤©æ©Ÿå™¨äººç‰ˆæœ¬ï¼ˆå–®æ¡ˆäº’å‹• / æ—©æœŸåŸå‹ï¼‰
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ source/     â† ä½ çš„ case1_raw.json, case2_raw.json, case3_raw.json
    â””â”€â”€ analysis/   â† ç”¢å‡ºåˆ†æçµæœï¼ˆeligibility + SNAD + recommendation + summaryï¼‰

```

---

# âœ… **ï¼ˆ1ï¼‰README.mdï¼ˆv3.2 æ›´æ–°å¾Œç‰ˆæœ¬ï¼‰**

````
# C2C Dispute Arbitration Pipeline (Modular v3.2)

This project implements a modular arbitration pipeline for C2C SNAD (Significantly Not As Described) dispute resolution.  
It follows a 3-stage structure and now includes:

- AI Summary Trigger (based on chat silence intervals)
- Full backend API for frontend integration
- Improved Stage 2 decision stability and JSON consistency

---

### Stage 1 â€” Extraction
Reads raw case JSON and normalizes:
- Listing info  
- Complaint summary  
- Highlighted messages  
- Timeline (chat log)  
- Transaction metadata (method, dispute hours, order completed)

---

### Stage 2 â€” LLM Decision Engine
Uses cloud model (OpenAI GPT-4o-mini) or local Gemma models to classify:

- SNAD (SND-501)  
- Neutral (SND-502)  
- Insufficient Evidence (SND-503)

LLM output is restricted to only:

```json
{
  "snadResult": {
    "label": "...",
    "reason": "..."
  }
}
````

Policies (ELI / SND / OUT / FEE) are referenced automatically inside the prompt.

---

### Stage 3 â€” Formatter

Adds:

* R1/R2/R3 eligibility flags
* Policy anchors
* Recommendation A/B
* AI-generated one-sentence Outcome summary
* Case full summary (Stage 3)

---

### **AI Summary Triggerï¼ˆv3.2 æ–°å¢ï¼‰**

`summary_trigger.py` detects:

* Long silence gaps between chat messages
* End-of-conversation summary moments

Auto-generates:

* Key issues
* Buyer/Seller claims
* Turning points
* Arbitration-relevant facts

Used by both backend API and future frontend chat UI.

---

### **Backend API Integrationï¼ˆv3.1 æ–°å¢ï¼‰**

`app/main.py` exposes:

```
GET /api/analysis/{case_id}
```

Frontend can directly embed analysis results:

* Eligibility
* SNAD decision
* Final recommendation
* Full AI summary

---

## Run the pipeline (CLI):

```
python src/arbitration_pipeline.py --case-id case1 --data-dir ./data/source --out-dir ./data/analysis --model openai:gpt-4o-mini
```

Input file:
`data/source/case1_raw.json`

Output file:
`data/analysis/case1_analysis.json`

---

## Run initial chatbot version:

```
python src/initial_judgement_chatbot.py --file ./data/source/case2_raw_raw.json --model openai:gpt-4o-mini
```

---

## Start API server (for frontend integration)

```
uvicorn app.main:app --reload
```

---

## Module Structure

```
src/pipeline/
â”‚
â”œâ”€â”€ extractor.py      # Stage 1 â€“ Parse raw case
â”œâ”€â”€ rflags.py         # Compute R1/R2/R3
â”œâ”€â”€ llm_stage2.py     # Stage 2 â€“ LLM SNAD classification + policy reference
â”œâ”€â”€ postprocess.py    # Clean JSON, enforce formatting rules
â”œâ”€â”€ policy.py         # Policy anchor utilities (ELI/SND/OUT/FEE)
â”œâ”€â”€ outcome_ai.py     # AI-generated outcome statement
â”œâ”€â”€ summary.py        # Build final caseSummary block
â””â”€â”€ build.py          # Orchestrates Stage 1/2/3 for API & CLI outputs
```

---

## Notes

This v3.2 modular version includes:

* Improved Stage 2 prompt accuracy
* Stable JSON formatting
* Auto-summary at conversation breakpoints
* Full backend â†’ frontend integration

It is functionally more reliable than v2 and earlier v3 versions.








